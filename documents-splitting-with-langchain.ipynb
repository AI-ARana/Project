{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b533a96",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.020829,
     "end_time": "2024-06-29T12:23:28.828469",
     "exception": false,
     "start_time": "2024-06-29T12:23:28.807640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">  Hands-On LangChain for LLM Applications Development: Documents Splitting </center>\n",
    "***\n",
    "\n",
    "Once you’ve loaded documents, you’ll often want to transform them to better suit your application. The simplest example is you may want to split a long document into smaller chunks that can fit into your model’s context window. \n",
    "\n",
    "When you want to deal with long pieces of text, it is necessary to split up that text into chunks. As simple as this sounds, there is a lot of potential complexity here. Ideally, you want to keep the semantically related pieces of text together. \n",
    "\n",
    "LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents. In this two-part practical article, we will explore the importance of document splitting, and the available LangChain text splitters and will explore four of them in depth. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7049c1c",
   "metadata": {
    "papermill": {
     "duration": 0.019332,
     "end_time": "2024-06-29T12:23:28.867614",
     "exception": false,
     "start_time": "2024-06-29T12:23:28.848282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### <a id=\"top\"></a>\n",
    "# <div style=\"box-shadow: rgb(60, 121, 245) 0px 0px 0px 3px inset, rgb(255, 255, 255) 10px -10px 0px -3px, rgb(31, 193, 27) 10px -10px, rgb(255, 255, 255) 20px -20px 0px -3px, rgb(255, 217, 19) 20px -20px, rgb(255, 255, 255) 30px -30px 0px -3px, rgb(255, 156, 85) 30px -30px, rgb(255, 255, 255) 40px -40px 0px -3px, rgb(255, 85, 85) 40px -40px; padding:20px; margin-right: 40px; font-size:30px; font-family: consolas; text-align:center; display:fill; border-radius:15px; color:rgb(60, 121, 245);\"><b>Table of contents</b></div>\n",
    "\n",
    "<div style=\"background-color: rgba(60, 121, 245, 0.03); padding:30px; font-size:15px; font-family: consolas;\">\n",
    "<ul>\n",
    "    <li><a href=\"#1\" target=\"_self\" rel=\" noreferrer nofollow\">1. Why do we need document splitting? </a></li> \n",
    "    <li><a href=\"#2\" target=\"_self\" rel=\" noreferrer nofollow\">2. Different types of LangChain splitters </a></li> \n",
    "    <li><a href=\"#3\" target=\"_self\" rel=\" noreferrer nofollow\">3. Introduction to recursive character text splitter & the character text splitter </a></li> \n",
    "    <li><a href=\"#4\" target=\"_self\" rel=\" noreferrer nofollow\">4. Diving deep in recursive splitting </a></li>\n",
    "    <li><a href=\"#5\" target=\"_self\" rel=\" noreferrer nofollow\">5. PDF loading & splitting </a></li>\n",
    "    <li><a href=\"#6\" target=\"_self\" rel=\" noreferrer nofollow\">6. Token splitting </a></li>\n",
    "    <li><a href=\"#7\" target=\"_self\" rel=\" noreferrer nofollow\">7. Context-aware splitting </a></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45466790",
   "metadata": {
    "papermill": {
     "duration": 0.020235,
     "end_time": "2024-06-29T12:23:28.907363",
     "exception": false,
     "start_time": "2024-06-29T12:23:28.887128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 1.  Why do we need document splitting? </b></div>\n",
    "\n",
    "\n",
    "Document splitting happens after you load your data into the document format. But before, it goes into the vector store, and this may seem really simple. \n",
    "\n",
    "You can just split the chunks according to the lengths of each character or something like that. But as an example of why this is both trickier and very important down the line, let’s take a look at this example here.\n",
    "\n",
    "We’ve got a sentence about an LLM model and some specifications. And if we did a simple splitting, we could end up with part of the sentence in one chunk, and the other part of the sentence in another chunk.\n",
    "\n",
    "Here is the whole sentence:\n",
    "\n",
    "**Falcon LLM is a generative large language model (LLM) that helps advance applications and use cases to future-proof our world. Today the Falcon 180B, 40B, 7.5B, and 1.3B parameter AI models.**\n",
    "\n",
    "\n",
    "Let's split it into two chunks:\n",
    "\n",
    "First chunk: \n",
    "\n",
    "**Falcon LLM is a generative large language model (LLM) that helps advance applications and use cases to future-proof our world**\n",
    "\n",
    "Second chunk:\n",
    "\n",
    "**Today the Falcon 180B, 40B, 7.5B, and 1.3B parameter AI models.**\n",
    "\n",
    "When we’re trying to answer a question down the line about what are the specifications of the Falcon LLM, we actually don’t have the right information in either chunk so it’s split apart. And so, we wouldn’t be able to answer this question correctly. So, there’s a lot of nuance and importance in splitting the chunks to get semantically relevant chunks together.\n",
    "\n",
    "The basis of all the text splitters in Lang Chain involves splitting on chunks in some chunk size with some chunk overlap. The figure below shows what that looks like. So, the chunk size corresponds to the size of a chunk, which can be measured in a few different ways. \n",
    "\n",
    "A chunk overlap is generally kept as a little overlap between two chunks, like a sliding window as we move from one to the other. This allows for the same piece of context to be at the end of one chunk and at the start of the other and helps create some notion of consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b86841",
   "metadata": {
    "papermill": {
     "duration": 0.019407,
     "end_time": "2024-06-29T12:23:28.946412",
     "exception": false,
     "start_time": "2024-06-29T12:23:28.927005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 2.  Different types of LangChain splitters </b></div>\n",
    "\n",
    "\n",
    "There are a lot of different types of splitters in Lang Chain, and we’ll cover a few of them in this article to give you an idea of how they work you are encouraged to try the rest on your own to see how they work. These text splitters vary across a bunch of dimensions. They also can vary on how they split the chunks, and what characters go into that. They can vary in how they measure the length of the chunks. Is it by characters? Is it by tokens? There are even some that use other smaller models to determine when the end of a sentence might be and use that as a way of splitting chunks.\n",
    "\n",
    "Another important part of splitting into chunks is also the metadata. Maintaining the same metadata across all chunks, but also adding in new pieces of metadata when relevant.\n",
    "\n",
    "**Here is a summary of the splitters available by the LangChain package:**\n",
    "\n",
    "* **CharacterTextSplitter()**: Implementation of splitting text that looks at characters. \n",
    "* **MarkdownHeaderTextSplitter()**: Implementation of splitting markdown files based on specified headers. \n",
    "* **TokenTextSplitter():** Implementation of splitting text that looks at tokens. \n",
    "* **SentenceTransformersTokenTextSplitter():** Implementation of splitting text that looks at tokens. \n",
    "* **RecursiveCharacterTextSplitter():** Implementation of splitting text that looks at characters. Recursively tries to split by different characters to find one that works.\n",
    "* **Language():** for CPP, Python, Ruby, Markdown etc \n",
    "* **NLTKTextSplitter():** Implementation of splitting text that looks at sentences using NLTK (Natural Language Tool Kit) \n",
    "* **SpacyTextSplitter():** Implementation of splitting text that looks at sentences using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6673be",
   "metadata": {
    "papermill": {
     "duration": 0.020296,
     "end_time": "2024-06-29T12:23:28.986973",
     "exception": false,
     "start_time": "2024-06-29T12:23:28.966677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 3.  Introduction to recursive character text splitter & the character text splitter </b></div>\n",
    "\n",
    "\n",
    "Let's start with two of the most common types of text splitters in Lang Chain. The recursive character text splitter and the character text splitter. We are going to try around with a few toy use cases to get a sense of how they work. We are going to set a relatively small chunk size of 26, and an even smaller chunk overlap of 4, so that we can see what these can do.\n",
    "\n",
    "Let’s initialize these text splitters as R splitter and a C splitter. And then let’s take a look at a few different use cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028fd31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:23:29.030794Z",
     "iopub.status.busy": "2024-06-29T12:23:29.030379Z",
     "iopub.status.idle": "2024-06-29T12:24:08.031727Z",
     "shell.execute_reply": "2024-06-29T12:24:08.030146Z"
    },
    "papermill": {
     "duration": 39.028412,
     "end_time": "2024-06-29T12:24:08.035000",
     "exception": false,
     "start_time": "2024-06-29T12:23:29.006588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.9.0 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.12.1 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\r\n",
      "jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install LangChain -q\n",
    "!pip install -U langchain-community -q\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "chunk_size =26\n",
    "chunk_overlap = 4\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452130fd",
   "metadata": {
    "papermill": {
     "duration": 0.019849,
     "end_time": "2024-06-29T12:24:08.075294",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.055445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s load in the first string. A, B, C, D, all the way down to Z. And let’s look at what happens when we use the various splitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe084a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:08.117747Z",
     "iopub.status.busy": "2024-06-29T12:24:08.117249Z",
     "iopub.status.idle": "2024-06-29T12:24:08.122638Z",
     "shell.execute_reply": "2024-06-29T12:24:08.121471Z"
    },
    "papermill": {
     "duration": 0.029475,
     "end_time": "2024-06-29T12:24:08.125151",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.095676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd975594",
   "metadata": {
    "papermill": {
     "duration": 0.019838,
     "end_time": "2024-06-29T12:24:08.165040",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.145202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's start with the RecursiveCharacterTextSplitter and see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0997ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:08.208543Z",
     "iopub.status.busy": "2024-06-29T12:24:08.208147Z",
     "iopub.status.idle": "2024-06-29T12:24:08.217124Z",
     "shell.execute_reply": "2024-06-29T12:24:08.215977Z"
    },
    "papermill": {
     "duration": 0.032769,
     "end_time": "2024-06-29T12:24:08.219601",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.186832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795d2a23",
   "metadata": {
    "papermill": {
     "duration": 0.019674,
     "end_time": "2024-06-29T12:24:08.259620",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.239946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When we split it with the RecursiveCharacterTextSplitter it still ends up as one string. This is because this is 26 characters long and we’ve specified a chunk size of 26. So, there’s actually no need to even do any splitting here. Now, let’s do it on a slightly longer string where it’s longer than the 26 characters that we’ve specified as the chunk size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00472e79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:08.302023Z",
     "iopub.status.busy": "2024-06-29T12:24:08.301240Z",
     "iopub.status.idle": "2024-06-29T12:24:08.308525Z",
     "shell.execute_reply": "2024-06-29T12:24:08.307441Z"
    },
    "papermill": {
     "duration": 0.030891,
     "end_time": "2024-06-29T12:24:08.310878",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.279987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59361a",
   "metadata": {
    "papermill": {
     "duration": 0.019742,
     "end_time": "2024-06-29T12:24:08.350932",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.331190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we can see that two different chunks are created. The first one ends at Z, so that’s 26 characters. The next one we can see starts with W, X, Y, Z. Those are the four chunk overlaps, And then it continues with the rest of the string.\n",
    "\n",
    "Let’s take a look at a slightly more complex string where we have a bunch of spaces between characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246e106d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:08.393491Z",
     "iopub.status.busy": "2024-06-29T12:24:08.392442Z",
     "iopub.status.idle": "2024-06-29T12:24:08.399797Z",
     "shell.execute_reply": "2024-06-29T12:24:08.398609Z"
    },
    "papermill": {
     "duration": 0.031359,
     "end_time": "2024-06-29T12:24:08.402441",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.371082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe05075f",
   "metadata": {
    "papermill": {
     "duration": 0.020636,
     "end_time": "2024-06-29T12:24:08.443303",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.422667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now see that it’s split into three chunks because there are spaces, so it takes up more space. And so, if we look at the overlap we can see that in the first one, there’s L and M, and L and M are then also present in the second one. That seems like only two characters but because of the space both in between the L and M, and then also, before the L and after the M that actually counts as the four that make up the chunk overlap.\n",
    "\n",
    "Let’s now try with the CharacterTextSplitter. We can see that when we run it doesn’t actually try to split it at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde9956",
   "metadata": {
    "papermill": {
     "duration": 0.020027,
     "end_time": "2024-06-29T12:24:08.483710",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.463683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The reason for this is that the CharacterTextSplitter splits on a single character and by default that character is a newline character. But here, there are no newlines.\n",
    "\n",
    "We can set the separator to be an empty space, we can see what happens then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c979896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:08.526315Z",
     "iopub.status.busy": "2024-06-29T12:24:08.525880Z",
     "iopub.status.idle": "2024-06-29T12:24:08.533841Z",
     "shell.execute_reply": "2024-06-29T12:24:08.532781Z"
    },
    "papermill": {
     "duration": 0.032308,
     "end_time": "2024-06-29T12:24:08.536314",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.504006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8b3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:39:24.283462Z",
     "iopub.status.busy": "2024-06-29T10:39:24.283071Z",
     "iopub.status.idle": "2024-06-29T10:39:24.290993Z",
     "shell.execute_reply": "2024-06-29T10:39:24.289442Z",
     "shell.execute_reply.started": "2024-06-29T10:39:24.283433Z"
    },
    "papermill": {
     "duration": 0.020286,
     "end_time": "2024-06-29T12:24:08.577143",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.556857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that here it’s split in the same way as before after we change the separator parameter to separate on space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef05bc1d",
   "metadata": {
    "papermill": {
     "duration": 0.020092,
     "end_time": "2024-06-29T12:24:08.617708",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.597616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"4\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 4.  Diving deep in recursive splitting </b></div>\n",
    "\n",
    "Now, let’s try it out on some more real-world examples. We’ve got this long paragraph here, and we can see that right about here, we have this double newline symbol which is a typical separator between paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef58128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:08.660970Z",
     "iopub.status.busy": "2024-06-29T12:24:08.659974Z",
     "iopub.status.idle": "2024-06-29T12:24:08.666404Z",
     "shell.execute_reply": "2024-06-29T12:24:08.665118Z"
    },
    "papermill": {
     "duration": 0.03074,
     "end_time": "2024-06-29T12:24:08.668969",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.638229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\"As the world grapples with the challenges of climate change, \\\n",
    "renewable energy emerges as a beacon of hope. Solar and wind power, \\\n",
    "in particular, are transforming the energy landscape, offering sustainable \\\n",
    "alternatives to traditional fossil fuels. \\n\\n  \\\n",
    "Governments and businesses globally are investing in clean energy \\\n",
    "initiatives to reduce carbon footprints and mitigate environmental impact. \\\n",
    "The shift towards renewables not only addresses environmental concerns \\\n",
    "but also fosters innovation, creating a brighter and more sustainable \\\n",
    "future for generations to come.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc14be",
   "metadata": {
    "papermill": {
     "duration": 0.021306,
     "end_time": "2024-06-29T12:24:08.711362",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.690056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s check out the length of this text, and we can see that it’s just about 600. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33374a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:08.754296Z",
     "iopub.status.busy": "2024-06-29T12:24:08.753846Z",
     "iopub.status.idle": "2024-06-29T12:24:08.760662Z",
     "shell.execute_reply": "2024-06-29T12:24:08.759551Z"
    },
    "papermill": {
     "duration": 0.031556,
     "end_time": "2024-06-29T12:24:08.763390",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.731834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e8d75",
   "metadata": {
    "papermill": {
     "duration": 0.08798,
     "end_time": "2024-06-29T12:24:08.873554",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.785574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s define two text splitters; Character Text Splitter and Recursive Character Text Splitter. We will work with the character text splitter as before with the space as a separator and then we’ll initialize the recursive character text splitter. Here, we pass in a list of separators, and these are the default separators but we’re just putting them to show better what’s going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de79405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:08.917045Z",
     "iopub.status.busy": "2024-06-29T12:24:08.916627Z",
     "iopub.status.idle": "2024-06-29T12:24:08.922656Z",
     "shell.execute_reply": "2024-06-29T12:24:08.921589Z"
    },
    "papermill": {
     "duration": 0.030924,
     "end_time": "2024-06-29T12:24:08.925242",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.894318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Character Text Splitter\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "\n",
    "# Recursive Character Text Splitter\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ddf60f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:08.968238Z",
     "iopub.status.busy": "2024-06-29T12:24:08.967838Z",
     "iopub.status.idle": "2024-06-29T12:24:08.973873Z",
     "shell.execute_reply": "2024-06-29T12:24:08.972753Z"
    },
    "papermill": {
     "duration": 0.030505,
     "end_time": "2024-06-29T12:24:08.976332",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.945827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Character Text Splitter\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "\n",
    "# Recursive Character Text Splitter\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b1cd8",
   "metadata": {
    "papermill": {
     "duration": 0.020437,
     "end_time": "2024-06-29T12:24:09.017661",
     "exception": false,
     "start_time": "2024-06-29T12:24:08.997224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For the Recursive Character Text Splitter, we have passed a list of separators. This list is double newline, single newline, space, and then nothing, an empty string. \n",
    "\n",
    "This means that when you’re splitting a piece of text it will first try to split it by double newlines. Then, if it still needs to split the individual chunks more it will go on to single newlines. Then, if it still needs to do more it goes on to the space. Finally, it will go character by character if it really needs to do that.\n",
    "\n",
    "Let's apply these two splitters to the text above and look at how they perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8f8e515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:09.062405Z",
     "iopub.status.busy": "2024-06-29T12:24:09.061973Z",
     "iopub.status.idle": "2024-06-29T12:24:09.069381Z",
     "shell.execute_reply": "2024-06-29T12:24:09.068318Z"
    },
    "papermill": {
     "duration": 0.033189,
     "end_time": "2024-06-29T12:24:09.071914",
     "exception": false,
     "start_time": "2024-06-29T12:24:09.038725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As the world grapples with the challenges of climate change, renewable energy emerges as a beacon of hope. Solar and wind power, in particular, are transforming the energy landscape, offering sustainable alternatives to traditional fossil fuels. \\n\\n Governments and businesses globally are investing in clean energy initiatives to reduce carbon footprints and mitigate environmental impact. The shift towards renewables not only addresses',\n",
       " 'environmental concerns but also fosters innovation, creating a brighter and more sustainable future for generations to come.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d0b7f",
   "metadata": {
    "papermill": {
     "duration": 0.020761,
     "end_time": "2024-06-29T12:24:09.113754",
     "exception": false,
     "start_time": "2024-06-29T12:24:09.092993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that the character text splitter splits on the spaces. So, we end up with this weird separation in the middle of the sentence. \n",
    "\n",
    "The Recursive Character Text Splitter first tries to split on double newlines, and so here it splits it up into two paragraphs. Even though the first one is shorter than the 450 characters, we specified this is probably a better split because now the two paragraphs that are each their own paragraphs are in chunks as opposed to being split in the middle of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4264e6f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:09.157511Z",
     "iopub.status.busy": "2024-06-29T12:24:09.157129Z",
     "iopub.status.idle": "2024-06-29T12:24:09.164359Z",
     "shell.execute_reply": "2024-06-29T12:24:09.163260Z"
    },
    "papermill": {
     "duration": 0.032244,
     "end_time": "2024-06-29T12:24:09.166939",
     "exception": false,
     "start_time": "2024-06-29T12:24:09.134695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As the world grapples with the challenges of climate change, renewable energy emerges as a beacon of hope. Solar and wind power, in particular, are transforming the energy landscape, offering sustainable alternatives to traditional fossil fuels.',\n",
       " 'Governments and businesses globally are investing in clean energy initiatives to reduce carbon footprints and mitigate environmental impact. The shift towards renewables not only addresses environmental concerns but also fosters innovation, creating a brighter and more sustainable future for generations to come.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ae184",
   "metadata": {
    "papermill": {
     "duration": 0.02092,
     "end_time": "2024-06-29T12:24:09.210220",
     "exception": false,
     "start_time": "2024-06-29T12:24:09.189300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let’s split it into even smaller chunks just to get a better understanding of how it works. We’ll also add a period separator. This is aimed at splitting in between sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "004fc9cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:09.254168Z",
     "iopub.status.busy": "2024-06-29T12:24:09.253710Z",
     "iopub.status.idle": "2024-06-29T12:24:09.262488Z",
     "shell.execute_reply": "2024-06-29T12:24:09.261311Z"
    },
    "papermill": {
     "duration": 0.033817,
     "end_time": "2024-06-29T12:24:09.265014",
     "exception": false,
     "start_time": "2024-06-29T12:24:09.231197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As the world grapples with the challenges of climate change, renewable energy emerges as a beacon of hope. Solar and wind power, in particular, are',\n",
       " 'transforming the energy landscape, offering sustainable alternatives to traditional fossil fuels.',\n",
       " 'Governments and businesses globally are investing in clean energy initiatives to reduce carbon footprints and mitigate environmental impact. The',\n",
       " 'shift towards renewables not only addresses environmental concerns but also fosters innovation, creating a brighter and more sustainable future for',\n",
       " 'generations to come.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca533ffa",
   "metadata": {
    "papermill": {
     "duration": 0.021492,
     "end_time": "2024-06-29T12:24:09.308180",
     "exception": false,
     "start_time": "2024-06-29T12:24:09.286688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we can see that it’s split into sentences, but the periods are actually in the wrong places. This is because of the regex that’s going on underneath the scenes. To fix this, we can actually specify a slightly more complicated regex with a look behind. To fix this, we can actually specify a slightly more complicated regex with a look behind. Now, if we run this, we can see that it’s split into sentences, and it’s split properly with the periods being in the right places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9a94315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:09.352536Z",
     "iopub.status.busy": "2024-06-29T12:24:09.352151Z",
     "iopub.status.idle": "2024-06-29T12:24:09.360870Z",
     "shell.execute_reply": "2024-06-29T12:24:09.359702Z"
    },
    "papermill": {
     "duration": 0.034005,
     "end_time": "2024-06-29T12:24:09.363438",
     "exception": false,
     "start_time": "2024-06-29T12:24:09.329433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As the world grapples with the challenges of climate change, renewable energy emerges as a beacon of hope. Solar and wind power, in particular, are',\n",
       " 'transforming the energy landscape, offering sustainable alternatives to traditional fossil fuels.',\n",
       " 'Governments and businesses globally are investing in clean energy initiatives to reduce carbon footprints and mitigate environmental impact. The',\n",
       " 'shift towards renewables not only addresses environmental concerns but also fosters innovation, creating a brighter and more sustainable future for',\n",
       " 'generations to come.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d9f8a1",
   "metadata": {
    "papermill": {
     "duration": 0.021261,
     "end_time": "2024-06-29T12:24:09.406117",
     "exception": false,
     "start_time": "2024-06-29T12:24:09.384856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"5\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 5.  PDF loading & splitting </b></div>\n",
    "\n",
    "Let’s now apply the document splitters on an even more real-world example with one of the PDFs that we worked with in the document loading article. Let’s load it in, and then let’s define the text splitter here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "941b5096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:09.451338Z",
     "iopub.status.busy": "2024-06-29T12:24:09.450534Z",
     "iopub.status.idle": "2024-06-29T12:24:11.391736Z",
     "shell.execute_reply": "2024-06-29T12:24:11.390612Z"
    },
    "papermill": {
     "duration": 1.966701,
     "end_time": "2024-06-29T12:24:11.394414",
     "exception": false,
     "start_time": "2024-06-29T12:24:09.427713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_file = '/kaggle/input/how-to-build-a-career-in-ai-pdf/eBook-How-to-Build-a-Career-in-AI.pdf'\n",
    "loader = PyPDFLoader(pdf_file)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef08ea4",
   "metadata": {
    "papermill": {
     "duration": 0.020944,
     "end_time": "2024-06-29T12:24:11.437220",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.416276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For the text splitter, we first pass the separator on the newline character. The chunk size is 1000 and the overlap is 150. Finally, we pass the length function using the len Python built-in function. This is the default, but we’re just specifying it for more clarity on what’s going on underneath the scenes, and this is counting the length of the characters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ae95dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:11.481533Z",
     "iopub.status.busy": "2024-06-29T12:24:11.481074Z",
     "iopub.status.idle": "2024-06-29T12:24:11.486698Z",
     "shell.execute_reply": "2024-06-29T12:24:11.485575Z"
    },
    "papermill": {
     "duration": 0.030615,
     "end_time": "2024-06-29T12:24:11.489069",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.458454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c2f28",
   "metadata": {
    "papermill": {
     "duration": 0.021059,
     "end_time": "2024-06-29T12:24:11.531433",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.510374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Because we now want to use documents, we’re using the split documents method, and we’re passing in a list of documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "167d06e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:11.576171Z",
     "iopub.status.busy": "2024-06-29T12:24:11.575423Z",
     "iopub.status.idle": "2024-06-29T12:24:11.584583Z",
     "shell.execute_reply": "2024-06-29T12:24:11.583439Z"
    },
    "papermill": {
     "duration": 0.034308,
     "end_time": "2024-06-29T12:24:11.587047",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.552739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeacfe31",
   "metadata": {
    "papermill": {
     "duration": 0.020952,
     "end_time": "2024-06-29T12:24:11.629824",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.608872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If we compare the length of those documents to the length of the original pages, we can see that there have been a bunch more documents that have been created as a result of this splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c33d1451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:11.674907Z",
     "iopub.status.busy": "2024-06-29T12:24:11.673815Z",
     "iopub.status.idle": "2024-06-29T12:24:11.681199Z",
     "shell.execute_reply": "2024-06-29T12:24:11.680014Z"
    },
    "papermill": {
     "duration": 0.032612,
     "end_time": "2024-06-29T12:24:11.683743",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.651131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8460c3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:11.729256Z",
     "iopub.status.busy": "2024-06-29T12:24:11.728360Z",
     "iopub.status.idle": "2024-06-29T12:24:11.735347Z",
     "shell.execute_reply": "2024-06-29T12:24:11.734250Z"
    },
    "papermill": {
     "duration": 0.032771,
     "end_time": "2024-06-29T12:24:11.738061",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.705290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f87c8f",
   "metadata": {
    "papermill": {
     "duration": 0.021447,
     "end_time": "2024-06-29T12:24:11.782631",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.761184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, let's print the content of the third document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "102568b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:11.828305Z",
     "iopub.status.busy": "2024-06-29T12:24:11.827840Z",
     "iopub.status.idle": "2024-06-29T12:24:11.835304Z",
     "shell.execute_reply": "2024-06-29T12:24:11.834160Z"
    },
    "papermill": {
     "duration": 0.032928,
     "end_time": "2024-06-29T12:24:11.837804",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.804876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAGE 3Table of \\nContentsIntroduction: Coding AI is the New Literacy.\\nChapter 1: Three Steps to Career Growth.\\nChapter 2: Learning Technical Skills for a \\nPromising AI Career.\\nChapter 3: Should You Learn Math to Get a Job \\nin AI?\\nChapter 4: Scoping Successful AI Projects.\\nChapter 5: Finding Projects that Complement \\nYour Career Goals.\\nChapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\nChapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\nChapter 8: Using Informational Interviews to Find \\nthe Right Job.\\nChapter 9: Finding the Right AI Job for You.\\nChapter 10: Keys to Building a Career in AI.\\nChapter 11: Overcoming Imposter Syndrome.\\nFinal Thoughts: Make Every Day Count.LEARNING\\nPROJECTS\\nJOB'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced73e3e",
   "metadata": {
    "papermill": {
     "duration": 0.022249,
     "end_time": "2024-06-29T12:24:11.882475",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.860226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"6\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 6.  Token splitting </b></div>\n",
    "\n",
    "In the previous sections, we have done all the splitting based on characters. But, there’s another way to split your text based on tokens. Since LLMs often have context windows that are designated by token count. Therefore it’s important to know what the tokens are, and where they appear. Then, we can split them to have a slightly more representative idea of how the LLM would view them.\n",
    "\n",
    "To have a better understanding of the difference between tokens and character splitters we will apply both to a piece of text and compare the results.\n",
    "\n",
    "Let’s initialize the token text splitter with a chunk size of 1 and a chunk overlap of 0. So, this will split any text into a list of the relevant tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1009b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:11.929299Z",
     "iopub.status.busy": "2024-06-29T12:24:11.927921Z",
     "iopub.status.idle": "2024-06-29T12:24:29.657984Z",
     "shell.execute_reply": "2024-06-29T12:24:29.656904Z"
    },
    "papermill": {
     "duration": 17.756228,
     "end_time": "2024-06-29T12:24:29.660858",
     "exception": false,
     "start_time": "2024-06-29T12:24:11.904630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\r\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\r\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tiktoken\r\n",
      "Successfully installed tiktoken-0.7.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6e5480",
   "metadata": {
    "papermill": {
     "duration": 0.022945,
     "end_time": "2024-06-29T12:24:29.706421",
     "exception": false,
     "start_time": "2024-06-29T12:24:29.683476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s create a small text example, and when we split it, we can see that it’s split into a bunch of different tokens, and they’re all a little bit different in terms of their length and the number of characters in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84883e0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:29.753813Z",
     "iopub.status.busy": "2024-06-29T12:24:29.753397Z",
     "iopub.status.idle": "2024-06-29T12:24:29.762208Z",
     "shell.execute_reply": "2024-06-29T12:24:29.761056Z"
    },
    "papermill": {
     "duration": 0.035474,
     "end_time": "2024-06-29T12:24:29.764683",
     "exception": false,
     "start_time": "2024-06-29T12:24:29.729209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"foo bar bazzyfoo\"\n",
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974313b",
   "metadata": {
    "papermill": {
     "duration": 0.026162,
     "end_time": "2024-06-29T12:24:29.814123",
     "exception": false,
     "start_time": "2024-06-29T12:24:29.787961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So, the first one is just foo then you’ve got a space, and then bar, and then you’ve got a space, and just the B then AZ then ZY, and then foo again. And this shows a little bit of the difference between splitting on characters versus splitting on tokens.\n",
    "\n",
    "Let’s apply this to the PDF that we loaded above, and in a similar way, we can call the split documents on the pages, and if we take a look at the first document, we have our new split document with the page content being roughly the title, and then we’ve got the metadata of the source and the page where it came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "052c8964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:29.861518Z",
     "iopub.status.busy": "2024-06-29T12:24:29.861081Z",
     "iopub.status.idle": "2024-06-29T12:24:30.186154Z",
     "shell.execute_reply": "2024-06-29T12:24:30.184959Z"
    },
    "papermill": {
     "duration": 0.351773,
     "end_time": "2024-06-29T12:24:30.188776",
     "exception": false,
     "start_time": "2024-06-29T12:24:29.837003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='PA', metadata={'source': '/kaggle/input/how-to-build-a-career-in-ai-pdf/eBook-How-to-Build-a-Career-in-AI.pdf', 'page': 0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(pages)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab11209",
   "metadata": {
    "papermill": {
     "duration": 0.022598,
     "end_time": "2024-06-29T12:24:30.235031",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.212433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can see here that the metadata of the source and the page is the same in the chunk as it was for the original document and so if we take a look at that to make sure pages [0] metadata, we can see that it lines up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dc011b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:30.284013Z",
     "iopub.status.busy": "2024-06-29T12:24:30.283584Z",
     "iopub.status.idle": "2024-06-29T12:24:30.290801Z",
     "shell.execute_reply": "2024-06-29T12:24:30.289591Z"
    },
    "papermill": {
     "duration": 0.035381,
     "end_time": "2024-06-29T12:24:30.293285",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.257904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '/kaggle/input/how-to-build-a-career-in-ai-pdf/eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0f732b",
   "metadata": {
    "papermill": {
     "duration": 0.022634,
     "end_time": "2024-06-29T12:24:30.339043",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.316409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is good it’s carrying through the metadata to each chunk appropriately, but there can also be cases where you actually want to add more metadata to the chunks as you split them. \n",
    "\n",
    "This can contain information like where in the document the chunk came from, from where it is relative to other things or concepts in the document, and generally this information can be used when answering questions to provide more context about what this chunk is exactly. \n",
    "\n",
    "To see a concrete example of this, let’s look at another type of text splitter that adds information to the metadata of each chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc899a3",
   "metadata": {
    "papermill": {
     "duration": 0.022733,
     "end_time": "2024-06-29T12:24:30.384933",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.362200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"7\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 7.  Context-aware splitting </b></div>\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together. However many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting. \n",
    "\n",
    "We can use MarkdownHeaderTextSplitter to preserve header metadata in our chunks. This splitter will split a markdown file based on the header or any subheaders and then it will add those headers as content to the metadata fields and that will get passed on along to any chunks that originate from those splits.\n",
    "\n",
    "**Let’s import the MarkdownHeaderTextSplitter using the code below:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "681e98b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:30.432946Z",
     "iopub.status.busy": "2024-06-29T12:24:30.432543Z",
     "iopub.status.idle": "2024-06-29T12:24:30.437614Z",
     "shell.execute_reply": "2024-06-29T12:24:30.436528Z"
    },
    "papermill": {
     "duration": 0.031866,
     "end_time": "2024-06-29T12:24:30.440011",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.408145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf3d8ea",
   "metadata": {
    "papermill": {
     "duration": 0.022794,
     "end_time": "2024-06-29T12:24:30.485929",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.463135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lets take this example to illustrate how it works. We have a title and then a subheader of chapter 1. We then have some sentences there, and then another section of an even smaller subheader, and then we jump back out to chapter 2, and some sentences there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e1e4b8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:30.535031Z",
     "iopub.status.busy": "2024-06-29T12:24:30.533900Z",
     "iopub.status.idle": "2024-06-29T12:24:30.539616Z",
     "shell.execute_reply": "2024-06-29T12:24:30.538382Z"
    },
    "papermill": {
     "duration": 0.033094,
     "end_time": "2024-06-29T12:24:30.542000",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.508906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Chapter 1\\n\\n Hi this is Section 1\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Section 2 \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Chapter 2\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce15ae0",
   "metadata": {
    "papermill": {
     "duration": 0.022683,
     "end_time": "2024-06-29T12:24:30.587810",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.565127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next we will define a list of the headers we want to split on and the names of those headers. So first, we’ve got a single hashtag and we’ll call that header 1. We’ve then got two hashtags, header 2, three hashtags, header 3. We can then initialize the markdown header text splitter with those headers, and then split the the example we have above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8984e27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:30.635998Z",
     "iopub.status.busy": "2024-06-29T12:24:30.635589Z",
     "iopub.status.idle": "2024-06-29T12:24:30.640985Z",
     "shell.execute_reply": "2024-06-29T12:24:30.639845Z"
    },
    "papermill": {
     "duration": 0.032202,
     "end_time": "2024-06-29T12:24:30.643391",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.611189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c196c64",
   "metadata": {
    "papermill": {
     "duration": 0.023303,
     "end_time": "2024-06-29T12:24:30.689770",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.666467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now lets split the example above on the splitters we gave in the previous code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edba371b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:30.739309Z",
     "iopub.status.busy": "2024-06-29T12:24:30.738303Z",
     "iopub.status.idle": "2024-06-29T12:24:30.744405Z",
     "shell.execute_reply": "2024-06-29T12:24:30.743002Z"
    },
    "papermill": {
     "duration": 0.033435,
     "end_time": "2024-06-29T12:24:30.746878",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.713443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6724d",
   "metadata": {
    "papermill": {
     "duration": 0.022723,
     "end_time": "2024-06-29T12:24:30.793425",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.770702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lets print the output to have a better understanding of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30c340f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:30.841895Z",
     "iopub.status.busy": "2024-06-29T12:24:30.841012Z",
     "iopub.status.idle": "2024-06-29T12:24:30.848309Z",
     "shell.execute_reply": "2024-06-29T12:24:30.847218Z"
    },
    "papermill": {
     "duration": 0.034209,
     "end_time": "2024-06-29T12:24:30.850727",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.816518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Chapter 1  \\nHi this is Section 1', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c6cbae",
   "metadata": {
    "papermill": {
     "duration": 0.024403,
     "end_time": "2024-06-29T12:24:30.898455",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.874052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If we take a look at a few of these examples, we can see the first one has the content, “Hi this is Chapter 1” “Hi this is Section 1.” and in the metadata, we have header 1, and then we have it as Title and header 2 as Chapter 1, and this is coming from right here in the example document above.\n",
    "\n",
    "Let’s take a look at the next one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "014ac95e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:30.947775Z",
     "iopub.status.busy": "2024-06-29T12:24:30.947347Z",
     "iopub.status.idle": "2024-06-29T12:24:30.954840Z",
     "shell.execute_reply": "2024-06-29T12:24:30.953616Z"
    },
    "papermill": {
     "duration": 0.035178,
     "end_time": "2024-06-29T12:24:30.957219",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.922041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Section 2', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d9edd",
   "metadata": {
    "papermill": {
     "duration": 0.023821,
     "end_time": "2024-06-29T12:24:31.004304",
     "exception": false,
     "start_time": "2024-06-29T12:24:30.980483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see here that we’ve jumped down into an even smaller subsection. We have got the content of “Hi this is Section 2” and now we’ve got not only header 1. But also header 2, and also header 3, and this is again coming from the content and names in the markdown document above.\n",
    "\n",
    "Let’s try this out on a real-world example. In a previous article, we loaded the notion directory using the notion directory loader and this loaded the files to markdown which is relevant for the markdown header splitter.\n",
    "\n",
    "**let’s load those documents using the NotionDirectoryLoader:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "377f07b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:31.053445Z",
     "iopub.status.busy": "2024-06-29T12:24:31.052544Z",
     "iopub.status.idle": "2024-06-29T12:24:31.078868Z",
     "shell.execute_reply": "2024-06-29T12:24:31.077708Z"
    },
    "papermill": {
     "duration": 0.054035,
     "end_time": "2024-06-29T12:24:31.081710",
     "exception": false,
     "start_time": "2024-06-29T12:24:31.027675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import NotionDirectoryLoader\n",
    "\n",
    "\n",
    "# Load the documents using NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"/kaggle/input/notiondb/Notion_DB\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Concatenate the content of all pages into a single string\n",
    "notion_text = ' '.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7904d3",
   "metadata": {
    "papermill": {
     "duration": 0.023224,
     "end_time": "2024-06-29T12:24:31.128692",
     "exception": false,
     "start_time": "2024-06-29T12:24:31.105468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we will define the **MarkdownHeaderTextSplitter** with header 1 as a single hashtag and header 2 as a double hashtag. We split the text and we get our splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69920dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:31.177629Z",
     "iopub.status.busy": "2024-06-29T12:24:31.176882Z",
     "iopub.status.idle": "2024-06-29T12:24:31.183230Z",
     "shell.execute_reply": "2024-06-29T12:24:31.182006Z"
    },
    "papermill": {
     "duration": 0.033686,
     "end_time": "2024-06-29T12:24:31.185722",
     "exception": false,
     "start_time": "2024-06-29T12:24:31.152036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(notion_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a824073",
   "metadata": {
    "papermill": {
     "duration": 0.022855,
     "end_time": "2024-06-29T12:24:31.232027",
     "exception": false,
     "start_time": "2024-06-29T12:24:31.209172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lets now print the first part of this splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b935fcc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:31.282044Z",
     "iopub.status.busy": "2024-06-29T12:24:31.281628Z",
     "iopub.status.idle": "2024-06-29T12:24:31.288999Z",
     "shell.execute_reply": "2024-06-29T12:24:31.287843Z"
    },
    "papermill": {
     "duration": 0.036065,
     "end_time": "2024-06-29T12:24:31.291609",
     "exception": false,
     "start_time": "2024-06-29T12:24:31.255544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='↓ Click the button below at the start of every week to clear the current meal plan.', metadata={'Header 1': 'Meal Planner'})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff8536",
   "metadata": {
    "papermill": {
     "duration": 0.023744,
     "end_time": "2024-06-29T12:24:31.339113",
     "exception": false,
     "start_time": "2024-06-29T12:24:31.315369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If we take a look at these results, we can see that the first one has content of the notion page. If you looked down to the metadata, we can see that we’ve loaded header 1 as Blendel’s employee handbook. \n",
    "\n",
    "If we print the second part of the results we can see that there will be a new header in the meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62807f0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:24:31.389477Z",
     "iopub.status.busy": "2024-06-29T12:24:31.388288Z",
     "iopub.status.idle": "2024-06-29T12:24:31.395310Z",
     "shell.execute_reply": "2024-06-29T12:24:31.394305Z"
    },
    "papermill": {
     "duration": 0.035478,
     "end_time": "2024-06-29T12:24:31.398232",
     "exception": false,
     "start_time": "2024-06-29T12:24:31.362754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='To edit meals from a specific day of the week, click on the meal entry you want to modify.  \\n[Weekly Plan](Meal%20Planner%2078127b2f0a0943808b94d7ff51873450/Weekly%20Plan%20f0e6db90b62b4b3fa432f1ba0cca0039.csv)', metadata={'Header 1': 'Weekly Plan'})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944c025",
   "metadata": {
    "papermill": {
     "duration": 0.023404,
     "end_time": "2024-06-29T12:24:31.445792",
     "exception": false,
     "start_time": "2024-06-29T12:24:31.422388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook, we have now gone over how to get semantically relevant chunks with appropriate metadata. In the next article, we will cover the next step of moving those chunks of data into a vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f9f7f",
   "metadata": {
    "papermill": {
     "duration": 0.023533,
     "end_time": "2024-06-29T12:24:31.493287",
     "exception": false,
     "start_time": "2024-06-29T12:24:31.469754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"box-shadow: rgba(240, 46, 170, 0.4) -5px 5px inset, rgba(240, 46, 170, 0.3) -10px 10px inset, rgba(240, 46, 170, 0.2) -15px 15px inset, rgba(240, 46, 170, 0.1) -20px 20px inset, rgba(240, 46, 170, 0.05) -25px 25px inset; padding:20px; font-size:30px; font-family: consolas; display:fill; border-radius:15px; color: rgba(240, 46, 170, 0.7)\"> <b> ༼⁠ ⁠つ⁠ ⁠◕⁠‿⁠◕⁠ ⁠༽⁠つ Thank You!</b></div>\n",
    "\n",
    "<p style=\"font-family:verdana; color:rgb(34, 34, 34); font-family: consolas; font-size: 16px;\"> 💌 Thank you for taking the time to read through my notebook. I hope you found it interesting and informative. If you have any feedback or suggestions for improvement, please don't hesitate to let me know in the comments. <br><br> 🚀 If you liked this notebook, please consider upvoting it so that others can discover it too. Your support means a lot to me, and it helps to motivate me to create more content in the future. <br><br> ❤️ Once again, thank you for your support, and I hope to see you again soon!</p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5174412,
     "sourceId": 8640145,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5304580,
     "sourceId": 8817749,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.396511,
   "end_time": "2024-06-29T12:24:32.038642",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-29T12:23:25.642131",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
